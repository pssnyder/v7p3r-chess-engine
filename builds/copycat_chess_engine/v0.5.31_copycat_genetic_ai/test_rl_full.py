# Full RL training pipeline test
print("ğŸš€ Starting Complete RL Training Pipeline Test...")

try:
    from reinforcement_training import ReinforcementTrainer
    
    # Create trainer with test config (smaller parameters)
    trainer = ReinforcementTrainer('config_test.yaml')
    print(f"âœ… Trainer initialized on {trainer.device}")
    print(f"   Actor params: {sum(p.numel() for p in trainer.actor.parameters()):,}")
    print(f"   Critic params: {sum(p.numel() for p in trainer.critic.parameters()):,}")
    
    # Start actual training (limited scope for testing)
    print("\nğŸ¯ Starting mini training run...")
    trainer.train()
    
    # Check if models were saved
    import os
    if os.path.exists("rl_actor_model.pth"):
        print("âœ… Actor model saved successfully")
    if os.path.exists("rl_critic_model.pth"):
        print("âœ… Critic model saved successfully")
    if os.path.exists("training_stats.json"):
        print("âœ… Training statistics saved successfully")
    
    print("\nğŸ¯ Complete RL training pipeline test successful!")
    
except Exception as e:
    print(f"âŒ Error: {e}")
    import traceback
    traceback.print_exc()
