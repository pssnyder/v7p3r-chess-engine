# v7p3r_rl_engine/v7p3r_rl_config.yaml
# Configuration file for the v7p3r Reinforcement Learning (RL) engine.

# Neural Network Architecture
hidden_dim: 512
dropout: 0.1

# PPO Hyperparameters
learning_rate: 3.0e-4
clip_ratio: 0.2
vf_coef: 0.5
ent_coef: 0.01

# Training Parameters
max_moves: 200
batch_size: 16
episodes_per_validation: 50

# Ruleset Integration
reward_ruleset: 'default_evaluation'  # Ruleset to use for reward shaping

# Stockfish Configuration for validation
stockfish_config:
  stockfish_path: 'engine_utilities/external_engines/stockfish/stockfish-windows-x86-64-avx2.exe'
  depth: 3
  movetime: 100
  elo_rating: 1500

# Model Persistence
model_path: 'v7p3r_rl_engine/v7p3r_rl_models/v7p3r_rl_model.pt'
save_frequency: 100  # Save model every N episodes

# CUDA Settings
use_cuda: true
device: 'auto'  # 'auto', 'cuda', or 'cpu'

# Logging
verbose_training: true
log_frequency: 10
