{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7ODx_xFn9HO"
      },
      "source": [
        "Okay, here's a detailed \"how-to\" guide in Markdown format, outlining the process of setting up your Beelink Mini PC as a central server and integrating your worker nodes. Think of this as your project's technical specification, mapping out each step to achieve your desired outcome.\n",
        "\n",
        "-----\n",
        "\n",
        "# Setting Up Your Local Chess Engine Distributed Compute Environment\n",
        "\n",
        "This guide will walk you through transforming your Beelink Mini PC into a robust central server for your chess engine's distributed compute environment, and then integrating your worker nodes (like your Orange Pi and other PCs) to report their results.\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "  * **Goal:** Establish a local server/client architecture where distributed chess engine worker nodes (running on Orange Pi, other PCs) send game results and data to a central database on a Beelink Mini PC, which also hosts a web-based dashboard for visualization.\n",
        "  * **Central Server (Product Owner / Main Server):** Beelink Mini S12 Pro (Intel N100, 16GB RAM, 500GB SSD)\n",
        "  * **Worker Nodes (Developers / Compute Engines):** Orange Pi (Quad-core Cortex-A7, 238MB RAM) and other local PCs.\n",
        "  * **Key Technologies:** Ubuntu Server, Docker, Docker Compose, PostgreSQL, Python (for data ingestion/dashboard backend), HTML/CSS/JS (for dashboard frontend).\n",
        "\n",
        "-----\n",
        "\n",
        "## Part 1: Setting Up the Beelink Mini PC (The Central Server)\n",
        "\n",
        "The Beelink, with its significantly better specifications, is perfectly suited to be the brains of your operation – handling the database, data ingestion, and the dashboard.\n",
        "\n",
        "### 1.1 Operating System Installation: Ubuntu Server\n",
        "\n",
        "**Why Ubuntu Server?**\n",
        "For a headless server that will run Docker and a database, Ubuntu Server is an excellent choice. It's free, highly optimized for server tasks, resource-efficient compared to Windows, boasts robust Docker support, and has a vast community for support.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1.  **Download Ubuntu Server ISO:**\n",
        "\n",
        "      * On a working computer, go to the official Ubuntu website ([ubuntu.com/download/server](https://ubuntu.com/download/server)) and download the latest **LTS (Long Term Support)** version (e.g., Ubuntu Server 22.04 LTS).\n",
        "\n",
        "2.  **Create a Bootable USB Drive:**\n",
        "\n",
        "      * Insert a USB flash drive (at least 4GB) into your working computer.\n",
        "      * Use a tool like **Rufus (Windows)** or **Etcher (Windows/macOS/Linux)** to \"burn\" the downloaded ISO image onto the USB drive. This makes the USB drive bootable.\n",
        "\n",
        "3.  **Install Ubuntu Server on Beelink:**\n",
        "\n",
        "      * Connect a monitor and keyboard to your Beelink Mini PC for the initial installation.\n",
        "      * Insert the bootable USB drive into the Beelink.\n",
        "      * Power on the Beelink and repeatedly press the key to enter the BIOS/Boot Menu (commonly `Del`, `F2`, `F7`, `F10`, or `F12` – check your Beelink's documentation if unsure).\n",
        "      * Select the USB drive as the boot device.\n",
        "      * Follow the on-screen prompts for installation:\n",
        "          * Choose your language.\n",
        "          * Select \"Install Ubuntu Server\".\n",
        "          * **Crucially:** When prompted for disk partitioning, choose to **\"Erase disk and install Ubuntu\"**. This will wipe the corrupt Windows installation.\n",
        "          * Configure your network (DHCP is usually fine for a home network). Note down the IP address if displayed, or you'll find it later.\n",
        "          * Create your user account (e.g., `pat`). Remember your username and password\\!\n",
        "          * **Select \"Install OpenSSH server\"** when prompted. This is vital for managing the Beelink headless after installation.\n",
        "          * Complete the installation. Once finished, remove the USB drive when prompted and press Enter to reboot.\n",
        "      * After reboot, you can disconnect the monitor and keyboard.\n",
        "\n",
        "### 1.2 Initial Server Configuration\n",
        "\n",
        "Now that Ubuntu Server is installed, you'll manage it remotely via SSH.\n",
        "\n",
        "1.  **Access via SSH:**\n",
        "\n",
        "      * From your main PC, open a terminal (Linux/macOS) or use an SSH client like PuTTY (Windows).\n",
        "      * Connect to your Beelink:\n",
        "        ```bash\n",
        "        ssh pat@<Beelink_IP_Address>\n",
        "        ```\n",
        "      * Replace `<Beelink_IP_Address>` with the actual IP address of your Beelink (you might find this from your router's connected devices list if you didn't note it during installation).\n",
        "\n",
        "2.  **Update System Packages:**\n",
        "\n",
        "      * It's crucial to update your system after installation to get the latest security patches and software.\n",
        "\n",
        "    <!-- end list -->\n",
        "\n",
        "    ```bash\n",
        "    sudo apt update\n",
        "    sudo apt upgrade -y\n",
        "    ```\n",
        "\n",
        "3.  **Configure Firewall (UFW):**\n",
        "\n",
        "      * The Uncomplicated Firewall (UFW) is installed by default on Ubuntu. It's vital for security.\n",
        "      * Allow SSH access (so you don't lock yourself out) and then enable the firewall.\n",
        "\n",
        "    <!-- end list -->\n",
        "\n",
        "    ```bash\n",
        "    sudo ufw allow ssh\n",
        "    sudo ufw enable\n",
        "    sudo ufw status verbose\n",
        "    ```\n",
        "\n",
        "      * Later, you'll need to allow ports for your database (PostgreSQL) and dashboard.\n",
        "\n",
        "### 1.3 Install Docker & Docker Compose\n",
        "\n",
        "Docker will allow you to package your database and applications into isolated containers, making management, updates, and portability incredibly easy.\n",
        "\n",
        "1.  **Install Docker Engine and Docker Compose Plugin:**\n",
        "    ```bash\n",
        "    # Add Docker's official GPG key:\n",
        "    sudo apt update\n",
        "    sudo apt install apt-transport-https ca-certificates curl software-properties-common -y\n",
        "    sudo install -m 0755 -d /etc/apt/keyrings\n",
        "    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n",
        "    sudo chmod a+r /etc/apt/keyrings/docker.gpg\n",
        "\n",
        "    # Add the Docker repository to Apt sources:\n",
        "    echo \\\n",
        "      \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n",
        "      \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n",
        "      sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
        "    sudo apt update\n",
        "\n",
        "    # Install Docker packages:\n",
        "    sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y\n",
        "    ```\n",
        "2.  **Add Your User to the `docker` Group:**\n",
        "      * This allows you to run Docker commands without `sudo`.\n",
        "    <!-- end list -->\n",
        "    ```bash\n",
        "    sudo usermod -aG docker pat # Replace 'pat' with your username\n",
        "    newgrp docker # Apply group changes immediately, or log out and back in\n",
        "    ```\n",
        "3.  **Verify Installation:**\n",
        "    ```bash\n",
        "    docker run hello-world\n",
        "    ```\n",
        "    You should see a \"Hello from Docker\\!\" message.\n",
        "\n",
        "### 1.4 Set Up Central Database (PostgreSQL with Docker Compose)\n",
        "\n",
        "While your chess engine uses SQLite locally, a central database requires a more robust, networked solution. PostgreSQL is an excellent choice for its reliability and features.\n",
        "\n",
        "1.  **Create Project Directory:**\n",
        "\n",
        "    ```bash\n",
        "    mkdir -p ~/chess-server/database\n",
        "    cd ~/chess-server/database\n",
        "    ```\n",
        "\n",
        "2.  **Create `docker-compose.yml` for PostgreSQL:**\n",
        "\n",
        "      * Use a text editor like `nano` (`nano docker-compose.yml`).\n",
        "\n",
        "    <!-- end list -->\n",
        "\n",
        "    ```yaml\n",
        "    version: '3.8'\n",
        "    services:\n",
        "      db:\n",
        "        image: postgres:15 # Using PostgreSQL version 15\n",
        "        restart: always\n",
        "        environment:\n",
        "          POSTGRES_DB: chess_results\n",
        "          POSTGRES_USER: your_db_user # <--- CHANGE THIS to a strong, unique username!\n",
        "          POSTGRES_PASSWORD: your_strong_password # <--- CHANGE THIS to a VERY strong, unique password!\n",
        "        volumes:\n",
        "          - ./data:/var/lib/postgresql/data # Persist database data\n",
        "        ports:\n",
        "          - \"5432:5432\" # Host_port:Container_port - Expose port 5432 to the host network\n",
        "        healthcheck:\n",
        "          test: [\"CMD-SHELL\", \"pg_isready -U your_db_user -d chess_results\"]\n",
        "          interval: 5s\n",
        "          timeout: 5s\n",
        "          retries: 5\n",
        "    ```\n",
        "\n",
        "      * **Important:** Replace `your_db_user` and `your_strong_password` with secure credentials.\n",
        "\n",
        "3.  **Start the Database Container:**\n",
        "\n",
        "    ```bash\n",
        "    docker compose up -d\n",
        "    ```\n",
        "\n",
        "    The `-d` flag runs it in \"detached\" mode (in the background).\n",
        "\n",
        "4.  **Allow Database Port in Firewall:**\n",
        "\n",
        "    ```bash\n",
        "    sudo ufw allow 5432/tcp\n",
        "    sudo ufw reload\n",
        "    ```\n",
        "\n",
        "5.  **Database Schema (Conceptual):**\n",
        "\n",
        "      * You'll need to design your database schema (tables, columns) to store the extracted data from your PGN, YAML, and log files.\n",
        "      * Example tables: `games` (for PGN data), `simulations` (for metadata from YAML), `worker_logs` (for log entries).\n",
        "      * You can create these tables using a PostgreSQL client (e.g., `psql` from a Docker container or directly if you install it) once the database is running.\n",
        "\n",
        "### 1.5 Data Ingestion & Dashboard Backend (Python with Docker)\n",
        "\n",
        "This will be a custom Python application that acts as an API gateway for your worker nodes and serves data to your dashboard.\n",
        "\n",
        "1.  **Conceptual Overview:**\n",
        "\n",
        "      * **Functionality:**\n",
        "          * **API Endpoint:** Expose an HTTP POST endpoint (e.g., `/submit_results`) where worker nodes can send their raw files (PGN, YAML, logs) or pre-parsed data.\n",
        "          * **Data Processing:** Parse the incoming PGN, YAML, and log data.\n",
        "          * **Database Insertion:** Connect to the PostgreSQL database and insert the parsed data into the appropriate tables.\n",
        "          * **Dashboard APIs:** Provide additional GET endpoints for your web dashboard to retrieve aggregated or raw data from the database for visualization.\n",
        "      * **Frameworks:** Use a lightweight Python web framework like **Flask** or **FastAPI**.\n",
        "      * **Containerization:** This application will run in its own Docker container, defined by a `Dockerfile` and integrated into your `docker-compose.yml`.\n",
        "\n",
        "2.  **Example `Dockerfile` (Conceptual):**\n",
        "\n",
        "      * Create a directory for your backend app (e.g., `~/chess-server/backend`).\n",
        "      * A simple `Dockerfile` would look like:\n",
        "        ```dockerfile\n",
        "        # backend/Dockerfile\n",
        "        FROM python:3.10-slim\n",
        "        WORKDIR /app\n",
        "        COPY requirements.txt .\n",
        "        RUN pip install -r requirements.txt\n",
        "        COPY . .\n",
        "        EXPOSE 8000 # Or whatever port your Flask/FastAPI app listens on\n",
        "        CMD [\"python\", \"app.py\"] # Or \"uvicorn app:app --host 0.0.0.0 --port 8000\" for FastAPI\n",
        "        ```\n",
        "\n",
        "3.  **Integrate into `docker-compose.yml` (Conceptual):**\n",
        "\n",
        "      * Add a new service to your existing `docker-compose.yml` (in `~/chess-server`):\n",
        "        ```yaml\n",
        "        # ~/chess-server/docker-compose.yml (updated)\n",
        "        version: '3.8'\n",
        "        services:\n",
        "          db:\n",
        "            # ... (PostgreSQL service as defined before) ...\n",
        "\n",
        "          backend:\n",
        "            build: ./backend # Points to the backend directory containing Dockerfile\n",
        "            restart: always\n",
        "            ports:\n",
        "              - \"8000:8000\" # Expose backend API port\n",
        "            environment:\n",
        "              DATABASE_URL: postgresql://your_db_user:your_strong_password@db:5432/chess_results # Container-to-container communication\n",
        "            depends_on:\n",
        "              db:\n",
        "                condition: service_healthy # Ensures DB is ready before backend starts\n",
        "        ```\n",
        "      * **Note:** The `DATABASE_URL` uses the service name `db` because Docker Compose sets up internal networking where services can resolve each other by their names.\n",
        "\n",
        "4.  **Allow Backend Port in Firewall:**\n",
        "\n",
        "      * If you expose your backend API on port 8000 (or another), allow it:\n",
        "\n",
        "    <!-- end list -->\n",
        "\n",
        "    ```bash\n",
        "    sudo ufw allow 8000/tcp\n",
        "    sudo ufw reload\n",
        "    ```\n",
        "\n",
        "### 1.6 Local Dashboard Frontend (Static Assets with Nginx in Docker)\n",
        "\n",
        "This will be the web interface for visualizing your chess engine data.\n",
        "\n",
        "1.  **Conceptual Overview:**\n",
        "\n",
        "      * **Technology:** Simple HTML, CSS, and JavaScript. The JavaScript will make requests to your Python backend's API endpoints to fetch data and then use charting libraries (e.g., Chart.js, D3.js) to display it.\n",
        "      * **Containerization:** Served by a lightweight web server like Nginx, also within a Docker container.\n",
        "\n",
        "2.  **Example Structure:**\n",
        "\n",
        "      * Create a directory for your frontend (e.g., `~/chess-server/frontend`).\n",
        "      * Place your `index.html`, `style.css`, `script.js` files here.\n",
        "\n",
        "3.  **Integrate into `docker-compose.yml` (Conceptual):**\n",
        "\n",
        "      * Add another service to your `docker-compose.yml`:\n",
        "        ```yaml\n",
        "        # ~/chess-server/docker-compose.yml (updated)\n",
        "        version: '3.8'\n",
        "        services:\n",
        "          db:\n",
        "            # ...\n",
        "\n",
        "          backend:\n",
        "            # ...\n",
        "\n",
        "          frontend:\n",
        "            image: nginx:alpine # Lightweight Nginx image\n",
        "            restart: always\n",
        "            volumes:\n",
        "              - ./frontend:/usr/share/nginx/html:ro # Mount your frontend files\n",
        "            ports:\n",
        "              - \"80:80\" # Or another port like 8080 if 80 is in use\n",
        "            depends_on:\n",
        "              - backend # Frontend depends on backend for data\n",
        "        ```\n",
        "      * **Access Dashboard:** Open your web browser and navigate to `http://<Beelink_IP_Address>`.\n",
        "\n",
        "4.  **Allow Frontend Port in Firewall:**\n",
        "\n",
        "    ```bash\n",
        "    sudo ufw allow 80/tcp # Or 8080/tcp if you chose that port\n",
        "    sudo ufw reload\n",
        "    ```\n",
        "\n",
        "-----\n",
        "\n",
        "## Part 2: Configuring Worker Nodes (Orange Pi & Other PCs)\n",
        "\n",
        "Your worker nodes will run the chess engine and send their results to the Beelink server.\n",
        "\n",
        "### 2.1 Modify Chess Engine Output & Data Publishing\n",
        "\n",
        "The core change here is to replace local file storage with network-based data submission.\n",
        "\n",
        "1.  **Update Chess Engine Script:**\n",
        "      * Locate the part of your Python chess engine script that writes game results (PGN), simulation metadata (YAML), and logs to files.\n",
        "      * Modify this logic to:\n",
        "          * **Read the generated data:** Even if it writes to temporary files first, read that data into Python variables.\n",
        "          * **Send data via HTTP POST:** Use Python's `requests` library to send this data to your Beelink's backend API endpoint.\n",
        "        <!-- end list -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gHsFmNTn9HT"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json # Or yaml, etc., depending on your data format\n",
        "\n",
        "BEELINK_API_URL = \"http://<Beelink_IP_Address>:8000/submit_results\" # Adjust port if different\n",
        "\n",
        "def send_results_to_server(pgn_data, yaml_data, log_data):\n",
        "    payload = {\n",
        "        \"pgn\": pgn_data,\n",
        "        \"yaml\": yaml_data,\n",
        "        \"logs\": log_data\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(BEELINK_API_URL, json=payload, timeout=30)\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        print(f\"Successfully submitted results: {response.json()}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error submitting results: {e}\")\n",
        "\n",
        "        # Example usage after a game/simulation is done\n",
        "        # pgn_content = \"...\"\n",
        "        # yaml_content = \"...\"\n",
        "        # log_content = \"...\"\n",
        "        # send_results_to_server(pgn_content, yaml_content, log_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiHFuZ6Un9HU"
      },
      "source": [
        "* Ensure all worker nodes (Orange Pi, other PCs) have the `requests` library installed (`pip install requests`).\n",
        "\n",
        "### 2.2 Orange Pi Specific Considerations\n",
        "\n",
        "The Orange Pi, while limited in RAM, can still act as a dedicated worker.\n",
        "\n",
        "1.  **Keep it Lean:** Only run the necessary services: the operating system and your chess engine with its modified Python script. Avoid unnecessary background processes.\n",
        "2.  **Python Environment:** Ensure your Python environment on the Orange Pi (likely an ARM-compatible Python distribution) is correctly set up with all dependencies for your chess engine and the `requests` library.\n",
        "3.  **Power & Stability:** Its low power consumption makes it ideal for continuous, long-running simulations.\n",
        "\n",
        "-----\n",
        "\n",
        "## Part 3: Future Considerations (Scaling & Advanced Orchestration)\n",
        "\n",
        "Once your core setup is stable, you can explore further enhancements.\n",
        "\n",
        "1.  **Automation & Monitoring:**\n",
        "\n",
        "      * **System Updates:** Set up `unattended-upgrades` on Ubuntu to automate security updates.\n",
        "      * **Docker Container Restarts:** Ensure `restart: always` is set for all your services in `docker-compose.yml`.\n",
        "      * **Monitoring Tools:** Consider lightweight monitoring tools (e.g., Prometheus with Grafana) if you want to track server health and application metrics, though this adds complexity.\n",
        "\n",
        "2.  **Security Hardening:**\n",
        "\n",
        "      * **SSH Keys:** Disable password authentication for SSH and exclusively use SSH keys for more secure access.\n",
        "      * **Database Access:** Configure your PostgreSQL database to only allow connections from specific IP addresses (your Beelink's internal Docker network and potentially your backend service).\n",
        "\n",
        "3.  **Kubernetes (K3s/MicroK8s) as a Future Option:**\n",
        "\n",
        "      * With the Beelink's 16GB RAM, running a lightweight Kubernetes distribution like **K3s** or **MicroK8s** becomes entirely feasible.\n",
        "      * This would allow you to:\n",
        "          * Orchestrate your database, backend, and frontend services with more advanced features (self-healing, scaling).\n",
        "          * Potentially manage dynamic deployments of your chess engine worker processes directly on the Beelink, or use it as a master node to coordinate worker pods across multiple home PCs if you expand to a larger cluster.\n",
        "      * **Recommendation:** Master the Docker Compose setup first. Kubernetes offers immense power but adds a significant layer of complexity.\n",
        "\n",
        "-----\n",
        "\n",
        "This guide should give you a solid roadmap to implement your vision for a powerful, yet cost-effective, local distributed compute environment. Good luck\\!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxUVWj9en9HV"
      },
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://github.com/KaminFay/base-deploy-image-generation\">https://github.com/KaminFay/base-deploy-image-generation</a></li>\n",
        "  <li><a href=\"https://github.com/246859/246859.github.io\">https://github.com/246859/246859.github.io</a></li>\n",
        "  <li><a href=\"https://github.com/jose-10000/adobe_commerce\">https://github.com/jose-10000/adobe_commerce</a></li>\n",
        "  <li><a href=\"https://www.scribd.com/document/775884484/Self-Hosting\">https://www.scribd.com/document/775884484/Self-Hosting</a></li>\n",
        "  <li><a href=\"https://github.com/Samiii777/AMD_MachineLearning\">https://github.com/Samiii777/AMD_MachineLearning</a></li>\n",
        "  </ol>\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
